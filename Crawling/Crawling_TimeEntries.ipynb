{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5820ed16",
   "metadata": {},
   "source": [
    "# Getting in through the login page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51792160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download needed packages\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import pandas as pd\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51c103a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriving username and password from alternate file\n",
    "bardough_username = config.username\n",
    "bardough_password = config.password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8b22871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the web page that we want open and log in.\n",
    "path = '/Users/sigfus/Desktop/Lífið/Github/Bardough/Crawling/chromedriver-mac-x64/chromedriver'\n",
    "s = Service(path)\n",
    "driver = webdriver.Chrome(service = s)\n",
    "driver.get('https://www.toasttab.com/login')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4604ffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Locate the username input field\n",
    "username = driver.find_element(By.ID, 'username') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56d2bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sign in with email first\n",
    "userid = bardough_username\n",
    "username.send_keys(userid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb7bac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the sign in button to prompt password\n",
    "sign_in_button = driver.find_element('xpath', '/html/body/div[2]/main/section/div/div/div/div/div/form/div[2]/button')\n",
    "sign_in_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd74bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the password input field\n",
    "password = driver.find_element(By.ID, 'password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9cf9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sign in with password second\n",
    "key = bardough_password\n",
    "password.send_keys(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3bf976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the sign in button to enter page\n",
    "sign_in_button = driver.find_element('xpath', '/html/body/div[2]/main/section/div/div/div/form/div[3]/button')\n",
    "sign_in_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98243c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get url of Time Entries page manually(under reports --> Employee Performance)\n",
    "url = 'https://www.toasttab.com/restaurants/admin/reports/home#selection-details'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d316a88",
   "metadata": {},
   "source": [
    "# Crawling Time Entries data for December 2022 - November 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771d3f5",
   "metadata": {},
   "source": [
    "## Code for crawling 2023 time entries data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5812433d",
   "metadata": {},
   "source": [
    "### Month changed for each iteration and total combined at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "331878b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawl time entry month by month\n",
    "\n",
    "nov_employee = []\n",
    "nov_job_title = []\n",
    "nov_in_date = []\n",
    "nov_out_date = []\n",
    "nov_total_hours = []\n",
    "nov_unpaid_break = []\n",
    "nov_paid_break = []\n",
    "nov_payable_hours = []\n",
    "\n",
    "page = 0\n",
    "# Change page count based on number of pages\n",
    "while page < 3:\n",
    "    \n",
    "    # Scan page\n",
    "    soup = bs(driver.page_source)\n",
    "    \n",
    "    # Crawl page\n",
    "    ## Odd rows\n",
    "    odd_rows = soup.find_all(class_ = 'odd')\n",
    "    odd_list = []\n",
    "    for row in odd_rows:\n",
    "        # Find all cells in the row and loop through them\n",
    "        odd_cells = row.find_all('td')\n",
    "        for cell in odd_cells:\n",
    "            # Extract text from each cell and convert to int if possible\n",
    "            odd_text = cell.get_text()\n",
    "            odd_list.append(odd_text)\n",
    "    ## Even rows\n",
    "    even_rows = soup.find_all(class_ = 'even')\n",
    "    even_list = []\n",
    "    for row in even_rows:\n",
    "        # Find all cells in the row and loop through them\n",
    "        even_cells = row.find_all('td')\n",
    "        for cell in even_cells:\n",
    "            # Extract text from each cell and convert to int if possible\n",
    "            even_text = cell.get_text()\n",
    "            even_list.append(even_text)\n",
    "    # Combine lists        \n",
    "    total_list = odd_list + even_list\n",
    "    \n",
    "    # Sort and append lists\n",
    "    employee = total_list[::8]\n",
    "    nov_employee.append(employee)\n",
    "    \n",
    "    job_title = total_list[1::8]\n",
    "    nov_job_title.append(job_title)\n",
    "    \n",
    "    in_date = total_list[2::8]\n",
    "    nov_in_date.append(in_date)\n",
    "    \n",
    "    out_date = total_list[3::8]\n",
    "    nov_out_date.append(out_date)\n",
    "    \n",
    "    total_hours = total_list[4::8]\n",
    "    nov_total_hours.append(total_hours)\n",
    "    \n",
    "    unpaid_break = total_list[5::8]\n",
    "    nov_unpaid_break.append(unpaid_break)\n",
    "    \n",
    "    paid_break = total_list[6::8]\n",
    "    nov_paid_break.append(paid_break)\n",
    "    \n",
    "    payable_hours = total_list[7::8]\n",
    "    nov_payable_hours.append(payable_hours)\n",
    "    \n",
    "    # Click to next page\n",
    "    time.sleep(4)\n",
    "    #Scroll down to the bottom of the page \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    #wait for page to be loaded\n",
    "    time.sleep(4)\n",
    "    #find and click 'next' button\n",
    "    #next_page_button = driver.find_element('xpath', '//*[@id=\"labor-time-entries-table_wrapper\"]/div[3]/div/div/ul/li[4]/a')\n",
    "    next_page_button = driver.find_element('xpath', '//*[@id=\"labor-time-entries-table_wrapper\"]/div[3]/div/div/ul/li[5]/a')\n",
    "    next_page_button.click()\n",
    "    time.sleep(4)\n",
    "    \n",
    "    page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "24267478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate pages (error in crawling/page switching)\n",
    "# For loop to select page's list\n",
    "for i in range(len(nov_employee)):\n",
    "    # Nested for loop to go through other pages' lists\n",
    "    for j in range(i+1, len(nov_employee)):\n",
    "        # Evaluation to see if page i's data is equal to other lists' data\n",
    "        if nov_employee[i] == nov_employee[j]:\n",
    "            # Show where the duplicates are found\n",
    "            print('The lists at index {} and {} are equal'.format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "986b45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine page nested lists into one huge list\n",
    "comp_nov_employee = [inner_item for outer_item in nov_employee for inner_item in outer_item]\n",
    "comp_nov_job_title = [inner_item for outer_item in nov_job_title for inner_item in outer_item]\n",
    "comp_nov_in_date = [inner_item for outer_item in nov_in_date for inner_item in outer_item]\n",
    "comp_nov_out_date = [inner_item for outer_item in nov_out_date for inner_item in outer_item]\n",
    "comp_nov_total_hours = [inner_item for outer_item in nov_total_hours for inner_item in outer_item]\n",
    "comp_nov_unpaid_break = [inner_item for outer_item in nov_unpaid_break for inner_item in outer_item]\n",
    "comp_nov_paid_break = [inner_item for outer_item in nov_paid_break for inner_item in outer_item]\n",
    "comp_nov_payable_hours = [inner_item for outer_item in nov_payable_hours for inner_item in outer_item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa70307c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222, 8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data frame for month\n",
    "nov_time_entries = {'Employee': comp_nov_employee, \n",
    "                'Job Title': comp_nov_job_title, \n",
    "                'In Date': comp_nov_in_date, \n",
    "                'Out Date': comp_nov_out_date, \n",
    "                'Total Hours': comp_nov_total_hours, \n",
    "                'Unpaid Break Time': comp_nov_unpaid_break, \n",
    "                'Paid Break Time': comp_nov_paid_break, \n",
    "                'Payable Hours': comp_nov_payable_hours\n",
    "                }\n",
    "\n",
    "nov_time_entries = pd.DataFrame(nov_time_entries)\n",
    "nov_time_entries.sort_values(by = \"In Date\")\n",
    "nov_time_entries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4d7f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download to CSV\n",
    "nov_time_entries.to_csv('/Users/sigfus/Desktop/nov_time_entries.csv', sep = ',', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee0ce7",
   "metadata": {},
   "source": [
    "# Combining monthly data frames into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ad807192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the 12 monthly data frames\n",
    "time_entries_seperate = [dec_22_time_entries, jan_time_entries, feb_time_entries, \n",
    "                         mar_time_entries, apr_time_entries, may_time_entries, \n",
    "                         jun_time_entries, jul_time_entries, aug_time_entries, \n",
    "                         sep_time_entries, oct_time_entries, nov_time_entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0ea469d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2293, 8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine them into one data frame with a new index rather than index from monthly data frames\n",
    "time_entries_full = pd.concat(time_entries_seperate, ignore_index = True)\n",
    "time_entries_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aac6c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download to CSV\n",
    "time_entries_full.to_csv('/Users/sigfus/Desktop/time_entries_full.csv', sep = ',', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd07225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
